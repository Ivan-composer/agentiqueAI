# `.cursorrules` for Agentique

## **Project Overview**

Agentique is an AI-powered platform allowing users to interact with “AI-twins” of content creators for personalized consultations. The project is structured as a **monorepo** with two main directories:

- **frontend/** – A Next.js application (using Tailwind CSS).  
- **backend/** – A FastAPI-based Python application.

We use **GitHub** for version control and **Cursor** as our local AI-powered coding assistant to help with generating, refactoring, and documenting code.

---

## **Monorepo Structure**

```
.
├── INSTRUCTIONS.md
├── README.md
├── backend
│   ├── README.md
│   ├── app
│   ├── main.py
│   ├── pyproject.toml
│   └── requirements.txt
├── folder-structure.txt
├── frontend
│   ├── README.md
│   ├── app
│   ├── components
│   ├── components.json
│   ├── hooks
│   ├── lib
│   ├── next-env.d.ts
│   ├── next.config.mjs
│   ├── package.json
│   ├── postcss.config.mjs
│   ├── public
│   ├── tailwind.config.ts
│   └── tsconfig.json
├── requirements.txt
└── uv.lock
```

---

## **Frontend Details**

- **Framework**: Next.js (React)  
- **Styling**: Tailwind CSS  

### Typical Scripts

- `npm install` to install dependencies  
- `npm run dev` to start the development server  
- `npm run build` for production build

---

## **Backend Details**

- **Framework**: FastAPI (Python)

### Key Dependencies

- `fastapi, uvicorn` for the server  
- `openai (>=1.0.0)` for embeddings generation  
- `pinecone-client (>=2.2.4)` for vector similarity search  
- `python-dotenv (>=1.0.0)` for environment variable management  
- `pydantic (>=2.4.2)` for data validation  
- `black (>=23.11.0)` for code formatting

### Typical Scripts

- `pip install -r requirements.txt` to install dependencies  
- `uvicorn main:app --reload` to start the FastAPI server  

---

## **AI Service Implementation**

The project includes a centralized AI service (`backend/app/services/ai_service.py`) that handles:

- **OpenAI** embeddings generation  
- **Pinecone** vector similarity search  
- Vector upserting and deletion  
- **Proper error handling and logging**  
  - For more advanced logging setup (like writing logs to files so that Cursor can see them independently of the server console), see **`logging-solution.md`**.  

Example AI Service Usage:

```python
from app.services.ai_service import AIService

# Initialize the service
ai_service = AIService()

# Generate embeddings
embedding = ai_service.generate_embedding("Your text here")

# Query similar vectors
results = ai_service.query_pinecone(embedding)
```

### **Single RAG Function (Unify Chat & Search)**

- If we plan **both** a single-agent chat (filter by `agent_id`) and a global search (no filter), we can unify them via **one** function, e.g.:

  ```python
  def rag_retrieve_and_summarize(query: str, agent_id: Optional[str] = None) -> str:
      """
      Perform RAG: embed the query, retrieve from Pinecone,
      optionally filter by agent_id, then build final context and call OpenAI.
      """
      ...
  ```
- This keeps the logic minimal and consistent across chat vs. search endpoints.

---

## **Coding Standards**

### General

- **Fewer lines of core logic** is ideal, but **thorough docstrings** and **comments** are strongly encouraged. Comments **do not** count against line constraints.  
- Keep code modular and well-structured.  
- Write descriptive commit messages (what was changed and why).  
- Use docstrings/comments for complex logic or unclear code sections.

### Frontend (Next.js & Tailwind)

- **Component Naming**: Use PascalCase for React components.  
- **Functional Components**: Prefer functional components.  
- **Tailwind Usage**:
  - Keep styling inline using Tailwind classes (`className="bg-blue-500 text-white p-4"`).
  - Avoid mixing external CSS files for basic styling if possible.  
- **Commenting**: Use JSDoc-style comments for component documentation.

Example:

```jsx
/**
 * A sample header component for the Agentique front-end.
 * @returns {JSX.Element} The rendered header.
 */
const Header = () => (
  <header className="bg-blue-500 p-4 text-white">
    <h1>Agentique</h1>
  </header>
);
export default Header;
```

### Backend (FastAPI & Python)

- **Naming**: Use snake_case for functions, variables, and file names.  
- **Type Hints**: Add Python type hints (`def my_function(param: str) -> int:`).  
- **Docstrings**: Provide docstrings for all functions/classes.  
- **Error Handling**: Minimal but direct `try/except` with short logging or raising `HTTPException` if something external fails (see `logging-solution.md` for advanced logging).

Example:

```python
def read_root() -> dict:
    """
    Root endpoint returning a welcome message.

    Returns:
        dict: A dictionary containing the welcome message.
    """
    return {"message": "Welcome to the Agentique backend!"}
```

#### **Handling Large Telegram Channels / Partial Ingestion**

- If Telegram channels are huge, store an offset (`last_msg_id` or `last_date`) in the DB to ingest partial data in batches.  
- This prevents timeouts or re-fetching old messages.

---

## **Linters & Formatters**

### Frontend: Prettier

Example `.prettierrc`:

```json
{
  "semi": true,
  "singleQuote": true,
  "trailingComma": "es5"
}
```

### Backend: Black

Example `pyproject.toml`:

```toml
[tool.black]
line-length = 88
target-version = ['py38']
```

---

## **Development Workflow**

- We use a **single environment** for MVP. No separate dev/prod environment.  
- Local Development (Cursor + GitHub):
  1. Clone project.  
  2. Open entire project folder in Cursor.  
  3. Make changes with Cursor’s AI assistance.  
  4. Commit & push to GitHub.

- **Testing & Iteration**:  
  - **Frontend** on localhost:3000  
  - **Backend** on localhost:8000 with docs at /docs  
  - Implement small test scripts or `pytest` to confirm /health endpoint, partial ingestion approach, etc.

---

## **Environment Variables and Secrets**

### Required for AI Service

```
OPENAI_API_KEY=your_openai_api_key_here
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=your_pinecone_environment  # e.g., us-west1-gcp
```

### Accessing Environment Variables

**Backend** (Python):
```python
import os
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
```

**Frontend** (Next.js):
- `.env.local` for local
- Access via `process.env.NEXT_PUBLIC_API_URL` or similar

---

## **Additional Tips**

1. **Minimal Code, Thorough Docstrings**  
   - Keep final logic lines minimal but do not limit comment lines or docstring lines.  
2. **Refer to Logging**  
   - For advanced file-based logging (so logs are visible even if you’re not in the same terminal), see **`logging-solution.md`**.  
3. **Partially Ingest Large Channels**  
   - Maintain an offset if the channel is huge; avoid re-downloading everything on each run.  
4. **Single RAG Function** for Chat vs. Search  
   - Optionally unify retrieval logic into one function with an `agent_id` filter or none.  
5. **Extend Error Handling** in AI Service  
   - Catch external service errors (OpenAI, Pinecone) and log/raise them in minimal code fashion.

---

**End of `.cursorrules`**.